{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import random \n",
    "\n",
    "ATLAS_URI=\"mongodb+srv://user:9ZDgfo2r3Rc6BCh6@tosleuth.mn1yhns.mongodb.net/?retryWrites=true&w=majority\"\n",
    "DB_NAME=\"tosleuth\"\n",
    "\n",
    "client = MongoClient(ATLAS_URI)\n",
    "db = client[DB_NAME]\n",
    "\n",
    "# Create collections for testing\n",
    "services = db[\"services\"]\n",
    "cases = db[\"cases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "services_data = services.find()\n",
    "# Only get cases classified as good or bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Set seed for reproducibility \u001b[39;00m\n\u001b[0;32m      4\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42069\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m test_services \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mservices_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\16479\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\random.py:456\u001b[0m, in \u001b[0;36mRandom.sample\u001b[1;34m(self, population, k, counts)\u001b[0m\n\u001b[0;32m    454\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    457\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[0;32m    458\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "# Randomly sample from services \n",
    "n = 10\n",
    "# Set seed for reproducibility \n",
    "random.seed(42069)\n",
    "test_services = random.sample(list(services_data), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shopify\n",
      "USSeek\n",
      "HP | Hewlett-Packard\n",
      "MIT App Inventor\n",
      "Movistar\n",
      "Roblox\n",
      "Turnitin\n",
      "ptgms Industries\n",
      "WikiHow\n",
      "Tubi\n"
     ]
    }
   ],
   "source": [
    "for service in test_services:\n",
    "    print(service[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating points for KidzSearch...: 100%|██████████| 4/4 [00:11<00:00,  2.98s/it]\n",
      "Validating points for Amazon...: 100%|██████████| 8/8 [00:19<00:00,  2.49s/it]\n",
      "Validating points for BlueMail...: 100%|██████████| 5/5 [00:13<00:00,  2.72s/it]\n",
      "Validating points for Free...: 100%|██████████| 10/10 [00:30<00:00,  3.00s/it]\n",
      "Validating points for Zoom Video Communications...: 100%|██████████| 17/17 [00:45<00:00,  2.67s/it]\n",
      "Validating points for Google Analytics...: 100%|██████████| 7/7 [00:18<00:00,  2.71s/it]\n",
      "Validating points for HuffPost...: 100%|██████████| 2/2 [00:05<00:00,  2.67s/it]\n",
      "Validating points for Truth Social...: 100%|██████████| 4/4 [00:10<00:00,  2.65s/it]\n",
      "Validating points for OneSignal...: 100%|██████████| 11/11 [00:27<00:00,  2.49s/it]\n",
      "Validating points for ToS;DR...: 100%|██████████| 7/7 [00:01<00:00,  4.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Testing part\n",
    "import requests\n",
    "import json \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "add_endpoint = \"http://127.0.0.1:8000/add\"\n",
    "query_endpoint = \"http://127.0.0.1:8000/query\"\n",
    "tosdr_point_url = \"https://edit.tosdr.org/points/\"\n",
    "\n",
    "# store our test result data here\n",
    "data = []\n",
    "\n",
    "for service in test_services:\n",
    "    doc_id_to_name = {}\n",
    "    for doc in service[\"documents\"]:\n",
    "        doc_obj = {\n",
    "            \"service\": service[\"name\"],\n",
    "            \"url\": doc[\"url\"],\n",
    "            \"name\": doc[\"name\"],\n",
    "            \"text\": doc[\"text\"]\n",
    "        }\n",
    "        # pprint.pprint(doc_obj)\n",
    "        response = requests.post(add_endpoint, json=doc_obj)\n",
    "        doc_id_to_name[doc[\"id\"]] = doc[\"name\"]\n",
    "    # print(f\"doc_id_to_name: {doc_id_to_name}\")\n",
    "    # Get 50/50 mix of valid and non valid cases\n",
    "    # only get approved points \n",
    "    valid_points = [\n",
    "        point for point in service[\"points\"] \n",
    "        if point[\"status\"] == 'approved'\n",
    "    ]\n",
    "    filtered_valid_cases = []\n",
    "    invalid_cases = []\n",
    "    # Get the case id for each point and check its rating\n",
    "    # We don't really care about neutral cases so filter those out\n",
    "    for point in valid_points:\n",
    "        valid_case_from_point = cases.find_one({\"id\": str(point[\"case_id\"])})\n",
    "        if valid_case_from_point[\"classification\"][\"human\"] in [\"good\", \"blocker\", \"bad\"]:\n",
    "            filtered_valid_cases.append(point)\n",
    "    # Get cases that do not apply to this service (negative cases) \n",
    "    invalid_cases = list(cases.aggregate(\n",
    "        [\n",
    "            {\n",
    "                \"$match\": {\n",
    "                    \"classification.human\": {\n",
    "                        \"$in\": [\"good\", \"blocker\", \"bad\"]\n",
    "                    },\n",
    "                    \"id\": {\n",
    "                        \"$nin\": [i[\"case_id\"] for i in filtered_valid_cases]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$sample\": {\n",
    "                    \"size\": len(filtered_valid_cases)\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    ))\n",
    "    # print(invalid_cases)\n",
    "\n",
    "    # valid_case_ids = [point[\"case_id\"] for point in valid_points]\n",
    "    \n",
    "    # for id in valid_case_ids:\n",
    "    #     case = cases.find_one({\"id\": id})\n",
    "    #     if case[\"classification\"][\"human\"] in [\"good\", \"blocker\"]:\n",
    "    #         filtered_valid_cases.append()\n",
    "    # invalid_cases = []\n",
    "    # count = 0\n",
    "    \n",
    "    # while count < len(valid_points):\n",
    "    #     for valid_case in random.sample(test_cases, len(test_cases)):\n",
    "    #         if valid_case[\"id\"] not in valid_case_ids:\n",
    "    #             invalid_cases.append(valid_case)\n",
    "    #             count += 1\n",
    "                \n",
    "    # Sample random valid cases:\n",
    "    valid_cases_random_sample = random.sample(filtered_valid_cases, len(filtered_valid_cases) // 2)\n",
    "    invalid_cases_random_sample = random.sample(invalid_cases, len(filtered_valid_cases) // 2)\n",
    "    # print(len(valid_cases_random_sample))\n",
    "    # print(len(invalid_cases_random_sample))\n",
    "    # print(valid_cases_random_sample)\n",
    "    # print('-'*100)\n",
    "    # print(invalid_cases_random_sample)\n",
    "    # Sample random invalid cases\n",
    "\n",
    "    invalid_llm_outputs = 0\n",
    "    false_negatives = 0\n",
    "    false_positives = 0\n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    # TODO: Batch processing of valid and invalid cases\n",
    "    # for idx in range(0, len(randomized_points)):\n",
    "    for idx in tqdm(range(0, len(valid_cases_random_sample)), desc=f\"Validating points for {service['name']}...\"):\n",
    "        valid_case = valid_cases_random_sample[idx]\n",
    "        invalid_case = invalid_cases_random_sample[idx]\n",
    "\n",
    "        # Go to point page and scrape the quote\n",
    "        # curr_point_url = tosdr_point_url + str(point[\"id\"])\n",
    "        # page = requests.get(curr_point_url)\n",
    "        # soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        # quote = soup.select_one(\".col-sm-10>blockquote\").get_text()\n",
    "        \n",
    "        # Valid case \n",
    "        # Handle missing document ids\n",
    "        try:\n",
    "            valid_doc_name = doc_id_to_name[valid_case[\"document_id\"]]\n",
    "        except KeyError:\n",
    "            valid_doc_name = \"PLACEHOLDER\"\n",
    "\n",
    "        valid_llm_query = {\n",
    "            \"tosdr_cases\": [valid_case[\"title\"]],\n",
    "            \"service\": service[\"name\"],\n",
    "            \"doc_name\": valid_doc_name\n",
    "        }\n",
    "        valid_llm_response = requests.post(url=query_endpoint, json=valid_llm_query)\n",
    "        if valid_llm_response.status_code == 200:\n",
    "            body = valid_llm_response.json()[\"results\"][0]\n",
    "            if body[\"error\"] == 2:\n",
    "                # LLM was not able to generate a valid JSON object and the backend\n",
    "                # couldn't parse it\n",
    "                invalid_llm_outputs += 1\n",
    "            elif body[\"error\"] == 1:\n",
    "                # LLM returned 0 on a valid case - false negative\n",
    "                false_negatives += 1\n",
    "            else:\n",
    "                # Validate true / false positives here\n",
    "                true_positives += 1\n",
    "            \n",
    "        # Invalid case\n",
    "        invalid_doc_name = \"PLACEHOLDER\"\n",
    "        \n",
    "        invalid_llm_query = {\n",
    "            \"tosdr_cases\": [invalid_case[\"title\"]],\n",
    "            \"service\": service[\"name\"],\n",
    "            \"doc_name\": invalid_doc_name\n",
    "        }\n",
    "        invalid_llm_response = requests.post(url=query_endpoint, json=invalid_llm_query)\n",
    "        if invalid_llm_response.status_code == 200:\n",
    "            body = invalid_llm_response.json()[\"results\"][0]\n",
    "            if body[\"error\"] == 2:\n",
    "                invalid_llm_outputs += 1 \n",
    "            elif body[\"error\"] == None:\n",
    "                # LLM should return 0 on a negative case - false positive\n",
    "                false_positives += 1 \n",
    "            elif body[\"error\"] == 1:\n",
    "                # Correct: LLM should return 0 on negative case\n",
    "                true_negatives += 1\n",
    "                # print(\"=\"*50)\n",
    "                # print(f\"query: {point['title']} point_id: {point['id']}\")\n",
    "                # print(\"-\"*50)\n",
    "                # print(quote)\n",
    "                # print(\"-\"*50)\n",
    "                # print(body[\"source_text\"])\n",
    "                # quote_tokenized = word_tokenize(quote)\n",
    "                # source_tokenized = word_tokenize(body[\"source_text\"])\n",
    "                # print(quote_tokenized, source_tokenized)\n",
    "                # diff = set(source_tokenized).intersection(quote_tokenized)\n",
    "                # print(\"-\"*50)\n",
    "                # print(diff)\n",
    "                # print(f\"{len(diff)} {len(quote_tokenized)} {len(source_tokenized)}\")\n",
    "                # if (\n",
    "                #     (len(diff) > len(quote_tokenized) // 2)\n",
    "                # ):\n",
    "                #     # The LLM's chosen text snippet and the real quote associated with the point\n",
    "                #     # are sufficiently similar if they share more than 50% of vocab (rough heuristic)\n",
    "                #     print(\"Text choice verified\")\n",
    "                #     pass\n",
    "                # else:\n",
    "                #     print(\"Invalid choice\")\n",
    "                #     invalid_choices += 1\n",
    "                # print(\"=\"*50)\n",
    "    data.append({\n",
    "        \"service\": service[\"name\"],\n",
    "        \"num_valid_cases_tested\": len(valid_cases_random_sample),\n",
    "        \"num_invalid_cases_tested\": len(invalid_cases_random_sample),\n",
    "        \"false_positives\": false_positives,\n",
    "        \"true_positives\": true_positives,\n",
    "        \"false_negatives\": false_negatives,\n",
    "        \"true_negatives\": true_negatives,\n",
    "        \"num_invalid_llm_outputs\": invalid_llm_outputs\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of invalid LLM outputs: 46/150\n",
      "Average overall failure rate: 30.7%\n",
      "Average failure rate per service: 32.4%\n",
      "Average false positive rate: 60.2%\n",
      "Average true positive rate: 51.0%\n",
      "Average true negative rate: 1.0%\n",
      "Average false negative rate: 0.0%\n",
      "Total false positive rate: 61.3%\n",
      "Total true positive rate: 54.7%\n",
      "Total true negative rate: 1.3%\n",
      "Total false negative rate: 0.0%\n",
      "====================================================================================================\n",
      "Accuracy: 0.4772727272727273\n",
      "Misclassification: 0.5227272727272727\n",
      "Precision: 0.47126436781609193\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.02127659574468085\n"
     ]
    }
   ],
   "source": [
    "total_invalid_llm_outputs = sum(i[\"num_invalid_llm_outputs\"] for i in data)\n",
    "total_valid_cases_tested = sum(i[\"num_valid_cases_tested\"] for i in data)\n",
    "total_invalid_cases_tested = sum(i[\"num_invalid_cases_tested\"] for i in data)\n",
    "total_avg_invalid_llm_output_rate = total_invalid_llm_outputs / (total_invalid_cases_tested + total_valid_cases_tested)\n",
    "print(f\"Total number of invalid LLM outputs: {total_invalid_llm_outputs}/{total_valid_cases_tested + total_invalid_cases_tested}\")\n",
    "print(f\"Average overall failure rate: {total_avg_invalid_llm_output_rate*100:.1f}%\")\n",
    "avg_invalid_llm_output_rate = sum(i['num_invalid_llm_outputs'] / (i['num_invalid_cases_tested']+i['num_valid_cases_tested']) for i in data) / len(data)\n",
    "print(f\"Average failure rate per service: {avg_invalid_llm_output_rate*100:.1f}%\" )\n",
    "avg_false_positive_rate = sum(\n",
    "    [\n",
    "        i[\"false_positives\"] / i[\"num_invalid_cases_tested\"]\n",
    "        for i in data\n",
    "    ]) / len(data)\n",
    "avg_true_positive_rate = sum(\n",
    "    [\n",
    "        i[\"true_positives\"] / i[\"num_valid_cases_tested\"]\n",
    "        for i in data\n",
    "    ]) / len(data)\n",
    "avg_true_negative_rate = sum(\n",
    "    [\n",
    "        i[\"true_negatives\"] / + i[\"num_invalid_cases_tested\"]\n",
    "        for i in data\n",
    "    ]) / len(data)\n",
    "avg_false_negative_rate = sum(\n",
    "    [\n",
    "        i[\"false_negatives\"] / i[\"num_valid_cases_tested\"]\n",
    "        for i in data\n",
    "    ]) / len(data)\n",
    "print(f\"Average false positive rate: {avg_false_positive_rate*100:.1f}%\")\n",
    "print(f\"Average true positive rate: {avg_true_positive_rate*100:.1f}%\")\n",
    "print(f\"Average true negative rate: {avg_true_negative_rate*100:.1f}%\")\n",
    "print(f\"Average false negative rate: {avg_false_negative_rate*100:.1f}%\")\n",
    "\n",
    "total_true_positives = sum(i[\"true_positives\"] for i in data)\n",
    "total_true_negatives = sum(i[\"true_negatives\"] for i in data)\n",
    "total_false_positives = sum(i[\"false_positives\"] for i in data)\n",
    "total_false_negatives = sum(i[\"false_negatives\"] for i in data)\n",
    "\n",
    "total_true_positive_rate = total_true_positives / (total_valid_cases_tested)\n",
    "total_false_positive_rate = total_false_positives / (total_invalid_cases_tested)\n",
    "total_true_negative_rate = total_true_negatives / (total_invalid_cases_tested)\n",
    "total_false_negative_rate = total_false_negatives / (total_valid_cases_tested)\n",
    "print(f\"Total false positive rate: {total_false_positive_rate*100:.1f}%\")\n",
    "print(f\"Total true positive rate: {total_true_positive_rate*100:.1f}%\")\n",
    "print(f\"Total true negative rate: {total_true_negative_rate*100:.1f}%\")\n",
    "print(f\"Total false negative rate: {total_false_negative_rate*100:.1f}%\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Accuracy: {(total_true_positives+total_true_negatives)/(total_true_positives+total_true_negatives+total_false_negatives+total_false_positives)}\")\n",
    "print(f\"Misclassification: {(total_false_positives+total_false_negatives)/(total_true_positives+total_true_negatives+total_false_negatives+total_false_positives)}\")\n",
    "print(f\"Precision: {(total_true_positives/(total_true_positives+total_false_positives))}\")\n",
    "print(f\"Sensitivity: {(total_true_positives)/(total_true_positives+total_false_negatives)}\")\n",
    "print(f\"Specificity: {total_true_negatives/(total_true_negatives+total_false_positives)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
